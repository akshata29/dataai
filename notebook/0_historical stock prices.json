{
	"name": "0_historical stock prices",
	"properties": {
		"folder": {
			"name": "Risk"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "dataaispk",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "ded25954-a11a-49d1-86dc-fbe25e3cfdbb"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/e2171f6d-2650-45e6-af7e-6d6e44ca92b1/resourceGroups/dataai/providers/Microsoft.Synapse/workspaces/dataaisynapsewks/bigDataPools/dataaispk",
				"name": "dataaispk",
				"type": "Spark",
				"endpoint": "https://dataaisynapsewks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/dataaispk",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.2",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"#Import the required libraries\n",
					"import pandas as pd\n",
					"import yfinance as yf\n",
					"#from yahoofinancials import YahooFinancials\n",
					"from datetime import datetime"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"diagram": {
						"activateDiagramType": 1,
						"chartConfig": {
							"category": "bar",
							"keys": [
								"Portfolio"
							],
							"values": [
								"Portfolio"
							],
							"yLabel": "Portfolio",
							"xLabel": "Portfolio",
							"aggregation": "COUNT",
							"aggByBackend": false
						},
						"aggData": "{\"Portfolio\":{\"Covid\":15,\"LongTerm\":9}}",
						"isSummary": false,
						"previewData": {
							"filter": null
						},
						"isSql": false
					},
					"collapsed": false
				},
				"source": [
					"# Read out CSV file with list of all tickers\n",
					"nqSdf = spark.read.load('abfss://risk@marketriskdl.dfs.core.windows.net/Portfolio/PortfolioCik.csv', \n",
					"    format='csv', \n",
					"    sep=\",\",\n",
					"    header=True)\n",
					"\n",
					"portfolioData = nqSdf.toPandas()\n",
					"display(portfolioData)"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"source": [
					"from azure.storage.blob import BlobServiceClient, ContainerClient\n",
					"from azure.storage.blob import BlobClient\n",
					"\n",
					"accountName = \"marketriskdl\"\n",
					"accountKey = \"2Gsb+co0ZjMiaiJxBHAPMhRyvY0NDz08r4WA2mDVgBd7RHcbykI+wUCYkIW9blVE/hnNXm+Z+mOzkppHi4BTag==\"\n",
					"containerName = \"risk\"\n",
					"connectionString = \"DefaultEndpointsProtocol=https;AccountName=marketriskdl;AccountKey=2Gsb+co0ZjMiaiJxBHAPMhRyvY0NDz08r4WA2mDVgBd7RHcbykI+wUCYkIW9blVE/hnNXm+Z+mOzkppHi4BTag==;EndpointSuffix=core.windows.net\""
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"source": [
					"# Get the stock price for all tickers and write it to CSV file\n",
					"#yahoo_financials = YahooFinancials(tickerTop10)\n",
					"\n",
					"#data = yahoo_financials.get_historical_price_data(start_date='2019-01-01', \n",
					"#                                                  end_date='2019-01-31', \n",
					"#                                                  time_interval='daily')\n",
					"finalColNames = [\"Portfolio\", \"Sector\", \"Cik\", \"Date\", \"Ticker\", \"AdjClose\"]\n",
					"\n",
					"for index, ticker in portfolioData.iterrows():\n",
					"    finalDf = pd.DataFrame(columns = finalColNames)\n",
					"    stockData = yf.download(ticker['Ticker'], period=\"max\", interval='1d', group_by='ticker', threads=True, progress=True)\n",
					"    for index, row in stockData.iterrows():\n",
					"        finalDf = finalDf.append({'Portfolio' : str(ticker['Portfolio']), 'Sector' : ticker['Sector'], 'Cik' : ticker['CIK'], 'Date' : index.date() , 'Ticker' : ticker['Ticker'], 'AdjClose' : row['Adj Close'] } , ignore_index=True)\n",
					"    output = finalDf.to_csv (index=False, header=True, encoding = \"utf-8\")\n",
					"    blobName = \"PortfolioQuotes/HistoricalData/\" + ticker['Ticker'] + \".csv\"\n",
					"    blob = BlobClient.from_connection_string(conn_str=connectionString, container_name=containerName, blob_name=blobName)\n",
					"    blob.upload_blob(output)\n",
					"    #blobService.create_blob_from_text(containerName, blobName, output)\n",
					"\n",
					""
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					""
				],
				"execution_count": null
			}
		]
	}
}