{
	"name": "2_stock timeseries forecast automl",
	"properties": {
		"folder": {
			"name": "Risk"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "dataaispk",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "22168657-2e31-4e96-b540-63a4fd0420d5"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/e2171f6d-2650-45e6-af7e-6d6e44ca92b1/resourceGroups/dataai/providers/Microsoft.Synapse/workspaces/dataaisynapsewks/bigDataPools/dataaispk",
				"name": "dataaispk",
				"type": "Spark",
				"endpoint": "https://dataaisynapsewks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/dataaispk",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.2",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"import azureml.core\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"import logging\n",
					"\n",
					"from azureml.core.workspace import Workspace\n",
					"from azureml.core.experiment import Experiment\n",
					"from azureml.train.automl import AutoMLConfig\n",
					"from azureml.automl.core.featurization import FeaturizationConfig"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"source": [
					"subscription_id = \"9c1bf73d-cfe5-4113-bc28-5f637bb222ad\"\n",
					"resource_group = \"marketrisk\"\n",
					"workspace_name = \"marketriskaml\"\n",
					"workspace_region = \"eastus\""
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"from azureml.core import Workspace\n",
					"\n",
					"try:\n",
					"    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
					"    # write the details of the workspace to a configuration file to the notebook library\n",
					"    ws.write_config()\n",
					"    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
					"except:\n",
					"    print(\"Workspace not accessible. Change your parameters or create a new workspace below\")"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"source": [
					"ws = Workspace.from_config()\n",
					"\n",
					"# choose a name for the run history container in the workspace\n",
					"experiment_name = 'automl-stockprice'\n",
					"experiment = Experiment(ws, experiment_name)\n",
					"output = {}\n",
					"output['SDK version'] = azureml.core.VERSION\n",
					"output['Subscription ID'] = ws.subscription_id\n",
					"output['Workspace'] = ws.name\n",
					"output['SKU'] = ws.sku\n",
					"output['Resource Group'] = ws.resource_group\n",
					"output['Location'] = ws.location\n",
					"output['Run History Name'] = experiment_name\n",
					"\n",
					"pd.set_option('display.max_colwidth', None)\n",
					"outputDf = pd.DataFrame(data = output, index = [''])"
				],
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"source": [
					"from azureml.core.compute import AmlCompute\n",
					"from azureml.core.compute import ComputeTarget\n",
					"\n",
					"# Choose a name for your cluster.\n",
					"amlcompute_cluster_name = \"cpu-cluster\"\n",
					"found = False\n",
					"\n",
					"# Check if this compute target already exists in the workspace.\n",
					"cts = ws.compute_targets\n",
					"if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
					"    found = True\n",
					"    print('Found existing compute target.')\n",
					"    compute_target = cts[amlcompute_cluster_name]\n",
					"\n",
					"if not found:\n",
					"    print('Creating a new compute target...')\n",
					"    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\", max_nodes = 2)\n",
					"    # Create the cluster\n",
					"    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
					"\n",
					"# Can poll for a minimum number of nodes and for a specific timeout.\n",
					"# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
					"compute_target.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"metadata": {
					"diagram": {
						"activateDiagramType": 1,
						"chartConfig": {
							"category": "bar",
							"keys": [
								"Portfolio"
							],
							"values": [
								"Ticker"
							],
							"yLabel": "Ticker",
							"xLabel": "Portfolio",
							"aggregation": "COUNT",
							"aggByBackend": true,
							"isValid": true,
							"inValidMsg": null,
							"series": "Ticker"
						},
						"aggData": "{\"PG\":{\"Covid\":1001}}",
						"isSummary": false,
						"previewData": {
							"filter": null
						},
						"isSql": false
					}
				},
				"source": [
					"# Read out CSV file with list of all tickers\n",
					"nqSdf = spark.read.load('abfss://risk@marketriskdl.dfs.core.windows.net/PortfolioQuotes/HistoricalData', \n",
					"    format='csv', \n",
					"    sep=\",\",\n",
					"    header=True)\n",
					"\n",
					"portfolioData = nqSdf.toPandas()\n",
					"display(portfolioData)"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"source": [
					"msftTicker = ['MSFT']\n",
					"msftData = portfolioData[portfolioData.Ticker.isin(msftTicker)]\n",
					"msftData = msftData.drop(columns=['Portfolio', 'Sector', 'Cik', 'Ticker'])\n",
					"msftData = msftData.set_index('Date')\n",
					"msftData"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"from pandas import DataFrame\n",
					"from pandas import Grouper\n",
					"from pandas import concat\n",
					"from pandas.plotting import register_matplotlib_converters\n",
					"from matplotlib import pyplot as plt\n",
					"\n",
					"register_matplotlib_converters()\n",
					"plt.figure(figsize=(20, 10))\n",
					"plt.tight_layout()"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"source": [
					"target_column_name = 'AdjClose'\n",
					"time_column_name = 'Date'\n",
					"time_series_id_column_names = []\n",
					"freq = 'M' #Monthly data"
				],
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"from azureml.core import Environment\n",
					"from azureml.core.conda_dependencies import CondaDependencies\n",
					"from azureml.train.estimator import Estimator\n",
					"from azureml.core.run import Run\n",
					"\n",
					"\n",
					"def split_fraction_by_grain(df, fraction, time_column_name,\n",
					"                            grain_column_names=None):\n",
					"\n",
					"    if not grain_column_names:\n",
					"        df['tmp_grain_column'] = 'grain'\n",
					"        grain_column_names = ['tmp_grain_column']\n",
					"\n",
					"    \"\"\"Group df by grain and split on last n rows for each group.\"\"\"\n",
					"    df_grouped = (df.sort_values(time_column_name)\n",
					"                  .groupby(grain_column_names, group_keys=False))\n",
					"\n",
					"    df_head = df_grouped.apply(lambda dfg: dfg.iloc[:-int(len(dfg) *\n",
					"                               fraction)] if fraction > 0 else dfg)\n",
					"\n",
					"    df_tail = df_grouped.apply(lambda dfg: dfg.iloc[-int(len(dfg) *\n",
					"                               fraction):] if fraction > 0 else dfg[:0])\n",
					"\n",
					"    if 'tmp_grain_column' in grain_column_names:\n",
					"        for df2 in (df, df_head, df_tail):\n",
					"            df2.drop('tmp_grain_column', axis=1, inplace=True)\n",
					"\n",
					"        grain_column_names.remove('tmp_grain_column')\n",
					"\n",
					"    return df_head, df_tail\n",
					"\n",
					"\n",
					"def split_full_for_forecasting(df, time_column_name,\n",
					"                               grain_column_names=None, test_split=0.2):\n",
					"    index_name = df.index.name\n",
					"\n",
					"    # Assumes that there isn't already a column called tmpindex\n",
					"\n",
					"    df['tmpindex'] = df.index\n",
					"\n",
					"    train_df, test_df = split_fraction_by_grain(\n",
					"        df, test_split, time_column_name, grain_column_names)\n",
					"\n",
					"    train_df = train_df.set_index('tmpindex')\n",
					"    train_df.index.name = index_name\n",
					"\n",
					"    test_df = test_df.set_index('tmpindex')\n",
					"    test_df.index.name = index_name\n",
					"\n",
					"    df.drop('tmpindex', axis=1, inplace=True)\n",
					"\n",
					"    return train_df, test_df\n",
					"\n",
					"\n",
					"def get_result_df(remote_run):\n",
					"    children = list(remote_run.get_children(recursive=True))\n",
					"    summary_df = pd.DataFrame(index=['run_id', 'run_algorithm',\n",
					"                                     'primary_metric', 'Score'])\n",
					"    goal_minimize = False\n",
					"    for run in children:\n",
					"        if('run_algorithm' in run.properties and 'score' in run.properties):\n",
					"            summary_df[run.id] = [run.id, run.properties['run_algorithm'],\n",
					"                                  run.properties['primary_metric'],\n",
					"                                  float(run.properties['score'])]\n",
					"            if('goal' in run.properties):\n",
					"                goal_minimize = run.properties['goal'].split('_')[-1] == 'min'\n",
					"\n",
					"    summary_df = summary_df.T.sort_values(\n",
					"        'Score',\n",
					"        ascending=goal_minimize).drop_duplicates(['run_algorithm'])\n",
					"    summary_df = summary_df.set_index('run_algorithm')\n",
					"    return summary_df"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"source": [
					"train, test = split_full_for_forecasting(msftData, time_column_name)\n",
					"train.to_csv(\"train.csv\")\n",
					"test.to_csv(\"test.csv\")\n",
					"\n",
					"datastore = ws.get_default_datastore()\n",
					"datastore.upload_files(files = ['./train.csv'], target_path = 'msft-dataset/tabular/', overwrite = True,show_progress = True)\n",
					"datastore.upload_files(files = ['./test.csv'], target_path = 'msft-dataset/tabular/', overwrite = True,show_progress = True)\n",
					"\n",
					"from azureml.core import Dataset\n",
					"train_dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'msft-dataset/tabular/train.csv')])\n",
					"test_dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'msft-dataset/tabular/test.csv')])"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"source": [
					"test"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"source": [
					"forecast_horizon = 12\n",
					"from azureml.automl.core.forecasting_parameters import ForecastingParameters\n",
					"forecasting_parameters = ForecastingParameters(\n",
					"    time_column_name=time_column_name, forecast_horizon=forecast_horizon\n",
					")\n",
					"\n",
					"automl_config = AutoMLConfig(task='forecasting',                             \n",
					"                             primary_metric='normalized_root_mean_squared_error',\n",
					"                             experiment_timeout_hours = 0.25,\n",
					"                             training_data=train_dataset,\n",
					"                             label_column_name=target_column_name,\n",
					"                             validation_data=test_dataset, \n",
					"                             verbosity=logging.INFO,\n",
					"                             compute_target=compute_target,\n",
					"                             max_concurrent_iterations=4,\n",
					"                             max_cores_per_iteration=-1,\n",
					"                             enable_dnn=True,\n",
					"                             forecasting_parameters=forecasting_parameters)"
				],
				"execution_count": 18
			},
			{
				"cell_type": "code",
				"source": [
					"remote_run = experiment.submit(automl_config, show_output= False)\n",
					"remote_run"
				],
				"execution_count": 19
			},
			{
				"cell_type": "code",
				"source": [
					"remote_run.wait_for_completion()"
				],
				"execution_count": 20
			},
			{
				"cell_type": "code",
				"source": [
					"summary_df = get_result_df(remote_run)\n",
					"summary_df"
				],
				"execution_count": 21
			},
			{
				"cell_type": "code",
				"source": [
					"time_column_name = 'Date'\n",
					"grain_column_names = ['Ticker', 'Portfolio']\n",
					"nseries = portfolioData.groupby(grain_column_names).ngroups\n",
					"print('Data contains {0} individual time-series.'.format(nseries))"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"source": [
					"use_tickers = ['MSFT', 'COST', 'WMT']\n",
					"data_subset = portfolioData[portfolioData.Ticker.isin(use_tickers)]\n",
					"nseries = data_subset.groupby(grain_column_names).ngroups\n",
					"print('Data subset contains {0} individual time-series.'.format(nseries))"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"source": [
					"n_test_periods = 20\n",
					"def split_last_n(df, n):\n",
					"\n",
					"    \"\"\"Group df and split on last n rows for each group.\"\"\"\n",
					"    df_grouped = (df.sort_values(time_column_name).groupby(grain_column_names, group_keys=False))\n",
					"    df_head = df_grouped.apply(lambda dfg: dfg.iloc[:-n])\n",
					"    df_tail = df_grouped.apply(lambda dfg: dfg.iloc[-n:])\n",
					"    return df_head, df_tail\n",
					"\n",
					"train, test = split_last_n(data_subset, n_test_periods)"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"metadata": {
					"diagram": {
						"activateDiagramType": 1,
						"chartConfig": {
							"category": "bar",
							"keys": [
								"Portfolio"
							],
							"values": [
								"Portfolio"
							],
							"yLabel": "Portfolio",
							"xLabel": "Portfolio",
							"aggregation": "COUNT",
							"aggByBackend": false
						},
						"aggData": "{\"Portfolio\":{\"Covid\":1001}}",
						"isSummary": false,
						"previewData": {
							"filter": null
						},
						"isSql": false
					}
				},
				"source": [
					"train.to_csv (r'./stock_train.csv', index = None, header=True)\n",
					"test.to_csv (r'./stock_test.csv', index = None, header=True) "
				],
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"source": [
					"datastore = ws.get_default_datastore()\n",
					"datastore.upload_files(files = ['./stock_train.csv', './stock_test.csv'], target_path = 'dataset/', overwrite = True,show_progress = True)\n",
					"\n",
					"#Letâ€™s now create the dataset that we will use for our training part:\n",
					"from azureml.core.dataset import Dataset\n",
					"train_dataset = Dataset.Tabular.from_delimited_files(path=datastore.path('dataset/stock_train.csv'))\n",
					"\n",
					"train_dataset.to_pandas_dataframe().tail()"
				],
				"execution_count": 18
			},
			{
				"cell_type": "code",
				"source": [
					"target_column_name = 'AdjClose'"
				],
				"execution_count": 19
			},
			{
				"cell_type": "code",
				"source": [
					"featurization_config = FeaturizationConfig()\n",
					"featurization_config.drop_columns = ['Sector']  # 'logQuantity' is a leaky feature, so we remove it.\n",
					"# Force the CPWVOL5 feature to be numeric type.\n",
					"#featurization_config.add_column_purpose('CPWVOL5', 'Numeric')\n",
					"# Fill missing values in the target column, Quantity, with zeros.\n",
					"#featurization_config.add_transformer_params('Imputer', ['Quantity'], {\"strategy\": \"constant\", \"fill_value\": 0})\n",
					"# Fill missing values in the INCOME column with median value.\n",
					"#featurization_config.add_transformer_params('Imputer', ['INCOME'], {\"strategy\": \"median\"})\n",
					"# Fill missing values in the Price column with forward fill (last value carried forward).\n",
					"#featurization_config.add_transformer_params('Imputer', ['Price'], {\"strategy\": \"ffill\"})"
				],
				"execution_count": 26
			},
			{
				"cell_type": "code",
				"source": [
					"from azureml.automl.core.forecasting_parameters import ForecastingParameters\n",
					"\n",
					"forecasting_parameters = ForecastingParameters(\n",
					"    time_column_name=time_column_name,\n",
					"    forecast_horizon=n_test_periods,\n",
					"    time_series_id_column_names=grain_column_names\n",
					")\n",
					"\n",
					"automl_config = AutoMLConfig(task='forecasting',\n",
					"                             debug_log='automl_errors.log',\n",
					"                             primary_metric='normalized_mean_absolute_error',\n",
					"                             experiment_timeout_hours=0.25,\n",
					"                             training_data=train_dataset,\n",
					"                             label_column_name=target_column_name,\n",
					"                             compute_target=compute_target,\n",
					"                             enable_early_stopping=True,\n",
					"                             featurization=featurization_config,\n",
					"                             n_cross_validations=3,\n",
					"                             verbosity=logging.INFO,\n",
					"                             max_cores_per_iteration=-1,\n",
					"                             forecasting_parameters=forecasting_parameters)"
				],
				"execution_count": 28
			},
			{
				"cell_type": "code",
				"source": [
					"remote_run = experiment.submit(automl_config, show_output=False)\n",
					"remote_run\n",
					"remote_run.wait_for_completion()"
				],
				"execution_count": 29
			},
			{
				"cell_type": "code",
				"source": [
					"best_run, fitted_model = remote_run.get_output()\n",
					"print(fitted_model.steps)\n",
					"model_name = best_run.properties['model_name']"
				],
				"execution_count": 30
			},
			{
				"cell_type": "code",
				"source": [
					"X_test = test\n",
					"y_test = X_test.pop(target_column_name).values\n",
					"X_test.head()"
				],
				"execution_count": 31
			},
			{
				"cell_type": "code",
				"source": [
					"# The featurized data, aligned to y, will also be returned.\n",
					"# This contains the assumptions that were made in the forecast\n",
					"# and helps align the forecast to the original data\n",
					"y_predictions, X_trans = fitted_model.forecast(X_test)"
				],
				"execution_count": 32
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"import numpy as np\n",
					"from pandas.tseries.frequencies import to_offset\n",
					"\n",
					"\n",
					"def align_outputs(y_predicted, X_trans, X_test, y_test, target_column_name,\n",
					"                  predicted_column_name='predicted',\n",
					"                  horizon_colname='horizon_origin'):\n",
					"    \"\"\"\n",
					"    Demonstrates how to get the output aligned to the inputs\n",
					"    using pandas indexes. Helps understand what happened if\n",
					"    the output's shape differs from the input shape, or if\n",
					"    the data got re-sorted by time and grain during forecasting.\n",
					"    Typical causes of misalignment are:\n",
					"    * we predicted some periods that were missing in actuals -> drop from eval\n",
					"    * model was asked to predict past max_horizon -> increase max horizon\n",
					"    * data at start of X_test was needed for lags -> provide previous periods\n",
					"    \"\"\"\n",
					"\n",
					"    if (horizon_colname in X_trans):\n",
					"        df_fcst = pd.DataFrame({predicted_column_name: y_predicted,\n",
					"                                horizon_colname: X_trans[horizon_colname]})\n",
					"    else:\n",
					"        df_fcst = pd.DataFrame({predicted_column_name: y_predicted})\n",
					"\n",
					"    # y and X outputs are aligned by forecast() function contract\n",
					"    df_fcst.index = X_trans.index\n",
					"\n",
					"    # align original X_test to y_test\n",
					"    X_test_full = X_test.copy()\n",
					"    X_test_full[target_column_name] = y_test\n",
					"\n",
					"    # X_test_full's index does not include origin, so reset for merge\n",
					"    df_fcst.reset_index(inplace=True)\n",
					"    X_test_full = X_test_full.reset_index().drop(columns='index')\n",
					"    together = df_fcst.merge(X_test_full, how='right')\n",
					"\n",
					"    # drop rows where prediction or actuals are nan\n",
					"    # happens because of missing actuals\n",
					"    # or at edges of time due to lags/rolling windows\n",
					"    clean = together[together[[target_column_name,\n",
					"                               predicted_column_name]].notnull().all(axis=1)]\n",
					"    return(clean)"
				],
				"execution_count": 33
			},
			{
				"cell_type": "code",
				"source": [
					"df_all = align_outputs(y_predictions, X_trans, X_test, y_test, target_column_name)\n",
					"\n",
					"from azureml.automl.core._vendor.automl.client.core.common import metrics\n",
					"from automl.client.core.common import constants\n",
					"\n",
					"# use automl metrics module\n",
					"scores = metrics.compute_metrics_regression(\n",
					"    df_all['predicted'],\n",
					"    df_all[target_column_name],\n",
					"    list(constants.Metric.SCALAR_REGRESSION_SET),\n",
					"    None, None, None)\n",
					"\n",
					"print(\"[Test data scores]\\n\")\n",
					"for key, value in scores.items():   \n",
					"    print('{}:   {:.3f}'.format(key, value))\n",
					""
				],
				"execution_count": 34
			},
			{
				"cell_type": "code",
				"source": [
					"# Plot outputs\n",
					"from matplotlib import pyplot as plt\n",
					"\n",
					"test_pred = plt.scatter(df_all[target_column_name], df_all['predicted'], color='b')\n",
					"test_test = plt.scatter(df_all[target_column_name], df_all[target_column_name], color='g')\n",
					"plt.legend((test_pred, test_test), ('prediction', 'truth'), loc='upper left', fontsize=8)\n",
					"plt.show()"
				],
				"execution_count": 35
			},
			{
				"cell_type": "code",
				"source": [
					""
				],
				"execution_count": null
			}
		]
	}
}